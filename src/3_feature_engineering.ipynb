{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1c81a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/ash/CascadeProjects/projects..../contrack_risk_analyser/.venv/lib/python3.14/site-packages (25.3)\n",
      "Collecting pip\n",
      "  Downloading pip-26.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading pip-26.0.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 25.3\n",
      "    Uninstalling pip-25.3:\n",
      "      Successfully uninstalled pip-25.3\n",
      "Successfully installed pip-26.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b8657d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/ash/CascadeProjects/projects..../contrack_risk_analyser/.venv/lib/python3.14/site-packages (3.0.1)\n",
      "Requirement already satisfied: numpy>=2.3.3 in /Users/ash/CascadeProjects/projects..../contrack_risk_analyser/.venv/lib/python3.14/site-packages (from pandas) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ash/CascadeProjects/projects..../contrack_risk_analyser/.venv/lib/python3.14/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ash/CascadeProjects/projects..../contrack_risk_analyser/.venv/lib/python3.14/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14a0ce3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.8.0-cp314-cp314-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.24.1 in /Users/ash/CascadeProjects/projects..../contrack_risk_analyser/.venv/lib/python3.14/site-packages (from scikit-learn) (2.4.2)\n",
      "Collecting scipy>=1.10.0 (from scikit-learn)\n",
      "  Downloading scipy-1.17.1-cp314-cp314-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting joblib>=1.3.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting threadpoolctl>=3.2.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.8.0-cp314-cp314-macosx_12_0_arm64.whl (8.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Downloading scipy-1.17.1-cp314-cp314-macosx_14_0_arm64.whl (20.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [scikit-learn][0m [scikit-learn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.3 scikit-learn-1.8.0 scipy-1.17.1 threadpoolctl-3.6.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#installing sklarn\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50333e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle #Used to save the trained TF-IDF vectorizer to disk.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # convert text into numerical features.\n",
    "from sklearn.model_selection import train_test_split # split dataset into training and testing sets.\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f469532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /Users/ash/CascadeProjects/projects..../contrack_risk_analyser/data/processed/processed_contracts.csv...\n",
      "Vocabulary size: 5000\n"
     ]
    }
   ],
   "source": [
    "def create_features(input_file, models_dir):\n",
    "    print(f\"Loading {input_file}...\")\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    X = df['cleaned_text'].fillna('')\n",
    "    y = df['risk_level']\n",
    "\n",
    "\n",
    "    # Creating TF-IDF Vectorizer\n",
    "    vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),  #1-word phrases (unigrams) and 2-word phrases (bigrams)\n",
    "    max_features=5000, #Limits vocabulary size to top 5000 most important words/phrases. \n",
    "    stop_words='english') #Removes common words\n",
    "\n",
    "    X_tfidf = vectorizer.fit_transform(X) # Converts text to numerical features.\n",
    "\n",
    "    print(f\"Vocabulary size: {len(vectorizer.vocabulary_)}\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    #! stratify=y : The distribution of High / Medium / Low is the same in both train and test sets.\n",
    "\n",
    "    os.makedirs(models_dir, exist_ok=True) #Creates models/ directory if it doesn't exist.\n",
    "    vec_path = os.path.join(models_dir, 'tfidf_vectorizer.pkl') #Builds save path.\n",
    "\n",
    "    with open(vec_path, 'wb') as f: # 'wb' = write binary.\n",
    "        pickle.dump(vectorizer, f) # Saves the trained TF-IDF vectorizer to disk.\n",
    "        # why save :- we must use the same vocabulary when predicting new contracts.\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "    except NameError:\n",
    "        base_dir = os.path.dirname(os.getcwd()) #Gets current file location\n",
    "    input_path = os.path.join(base_dir, \"data\", \"processed\", \"processed_contracts.csv\")\n",
    "    models_dir = os.path.join(base_dir, \"models\") # Directory to save trained models and vectorizers.\n",
    "    \n",
    "    create_features(input_path, models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e02777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92190cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
